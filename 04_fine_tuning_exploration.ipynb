{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "handled-player",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "tough-economics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import library\n",
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import metrics, losses, optimizers\n",
    "from tensorflow.keras import backend, layers, models, callbacks, utils\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.applications.xception import preprocess_input\n",
    "\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "defensive-subscriber",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define plot function\n",
    "def plot_loss(history):\n",
    "    loss = history.history[\"loss\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "    plt.plot(epochs, loss, label=\"training loss\")\n",
    "    plt.plot(epochs, val_loss, label=\"valid loss\")\n",
    "    plt.title(\"Training & Valid Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_acc(history):\n",
    "    acc = history.history[\"categorical_accuracy\"]\n",
    "    val_acc = history.history[\"val_categorical_accuracy\"]\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "    plt.plot(epochs, acc, label=\"training acc\")\n",
    "    plt.plot(epochs, val_acc, label=\"valid acc\")\n",
    "    plt.title(\"Training & Valid Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "theoretical-royal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our working directory\n",
    "img_dir = os.path.join(\"../subset_stanford_online_products/\")\n",
    "save_dir = os.path.join(\"models/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "realistic-peeing",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = (299, 299, 3)\n",
    "batch_size = 32\n",
    "\n",
    "lr_classifier = 1e-4\n",
    "epoch_classifier = 10\n",
    "\n",
    "lr_tuning = 1e-6\n",
    "epoch_tuning = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "complimentary-alert",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = image.ImageDataGenerator(rotation_range=40,\n",
    "                                         width_shift_range=0.2,\n",
    "                                         height_shift_range=0.2,\n",
    "                                         shear_range=0.2,\n",
    "                                         zoom_range=0.2,\n",
    "                                         horizontal_flip=True,\n",
    "                                         fill_mode=\"nearest\",\n",
    "                                         validation_split=0.2)\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen = image.ImageDataGenerator(validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cheap-shareware",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9600 images belonging to 12 classes.\n",
      "Found 2400 images belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    # This is the target directory\n",
    "    img_dir,\n",
    "    subset=\"training\",\n",
    "    # All images will be resized to 299 x 299\n",
    "    target_size=img_size[:2],\n",
    "    batch_size=batch_size,\n",
    "    # Since we use categorical_crossentropy loss, we need categorical labels\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=1234)\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    img_dir,\n",
    "    subset=\"validation\",\n",
    "    target_size=img_size[:2],\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "korean-romania",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    conv_base = Xception(weights=\"imagenet\",\n",
    "                         include_top=False,\n",
    "                         input_shape=img_size)\n",
    "\n",
    "    conv_base.trainable = False\n",
    "\n",
    "    input_layer = keras.Input(shape=img_size)\n",
    "    x = preprocess_input(input_layer)\n",
    "    x = conv_base(x, training=False)\n",
    "    x1 = layers.GlobalAveragePooling2D()(x)\n",
    "    x2 = layers.GlobalMaxPooling2D()(x)\n",
    "    x = layers.Concatenate()([x1, x2])\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(512, activation=\"relu\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    output_layer = layers.Dense(12, activation=\"softmax\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    return conv_base, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dedicated-fossil",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "Number of devices: 2\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print(\"Number of devices: {}\".format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "sixth-needle",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_callbacks = [\n",
    "    callbacks.CSVLogger(os.path.join(save_dir, \"log_training.csv\"),\n",
    "                        separator=\",\",\n",
    "                        append=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "western-simple",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    }
   ],
   "source": [
    "# Open a strategy scope.\n",
    "with strategy.scope():\n",
    "    # Everything that creates variables should be under the strategy scope.\n",
    "    # In general this is only model construction & `compile()`.\n",
    "    conv_base, model = create_model()\n",
    "    model.compile(loss=losses.CategoricalCrossentropy(),\n",
    "                  optimizer=optimizers.Adam(learning_rate=lr_classifier),\n",
    "                  metrics=[metrics.CategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "photographic-rates",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"xception\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 149, 149, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 149, 149, 32) 128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 149, 149, 32) 0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 147, 147, 64) 18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 147, 147, 64) 256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 147, 147, 64) 0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 147, 147, 128 8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 147, 147, 128 512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 147, 147, 128 0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 147, 147, 128 17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 147, 147, 128 512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 74, 74, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 74, 74, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 74, 74, 128)  512         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 74, 74, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 74, 74, 128)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 74, 74, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 74, 74, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 74, 74, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 74, 74, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 74, 74, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 37, 37, 256)  32768       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 37, 37, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 37, 37, 256)  1024        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 37, 37, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 37, 37, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 37, 37, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 37, 37, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 37, 37, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 37, 37, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 37, 37, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 19, 19, 728)  186368      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 19, 19, 728)  0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 19, 19, 728)  2912        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 19, 19, 728)  0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 19, 19, 728)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 19, 19, 728)  0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 19, 19, 728)  0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 19, 19, 728)  0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 19, 19, 728)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 19, 19, 728)  0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 19, 19, 728)  0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 19, 19, 728)  0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 19, 19, 728)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 19, 19, 728)  0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 19, 19, 728)  0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 19, 19, 728)  0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 19, 19, 728)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 19, 19, 728)  0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 19, 19, 728)  0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 19, 19, 728)  0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 19, 19, 728)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 19, 19, 728)  0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 19, 19, 728)  0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 19, 19, 728)  0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 19, 19, 728)  0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 19, 19, 728)  0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 19, 19, 728)  0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 19, 19, 728)  0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 19, 19, 728)  0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 19, 19, 728)  0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 19, 19, 728)  0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 19, 19, 728)  0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 19, 19, 728)  0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 19, 19, 728)  0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 19, 19, 1024) 752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 19, 19, 1024) 4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 10, 10, 1024) 745472      add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 10, 10, 1024) 0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 10, 10, 1024) 4096        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 10, 10, 1024) 0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 10, 10, 1536) 1582080     add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 10, 10, 1536) 6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 10, 10, 1536) 0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 10, 10, 2048) 3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 10, 10, 2048) 8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 10, 10, 2048) 0           block14_sepconv2_bn[0][0]        \n",
      "==================================================================================================\n",
      "Total params: 20,861,480\n",
      "Trainable params: 0\n",
      "Non-trainable params: 20,861,480\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "pressed-material",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_truediv (TensorFlow [(None, 299, 299, 3) 0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_sub (TensorFlowOpLa [(None, 299, 299, 3) 0           tf_op_layer_truediv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "xception (Model)                (None, 10, 10, 2048) 20861480    tf_op_layer_sub[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           xception[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d (GlobalMax (None, 2048)         0           xception[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 4096)         0           global_average_pooling2d[0][0]   \n",
      "                                                                 global_max_pooling2d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 4096)         16384       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 4096)         0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          2097664     dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 512)          2048        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 512)          0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 12)           6156        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 22,983,732\n",
      "Trainable params: 2,113,036\n",
      "Non-trainable params: 20,870,696\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "unlikely-console",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "75/75 [==============================] - 12s 165ms/step - loss: 3.3014 - categorical_accuracy: 0.0737\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[3.3013506285349528, 0.07375]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(validation_generator, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "impressed-spine",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\n",
    "    os.path.join(\"transfer_learning_classifier_preprocess_input.h5\"),\n",
    "    by_name=False,\n",
    "    skip_mismatch=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "differential-tampa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "75/75 [==============================] - 11s 141ms/step - loss: 0.7051 - categorical_accuracy: 0.7708\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7051020739475886, 0.7708333]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(validation_generator, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fleet-convergence",
   "metadata": {},
   "source": [
    "# Fine tune from add 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "proud-lighting",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del (conv_base)\n",
    "    del (model)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "arabic-sunset",
   "metadata": {},
   "outputs": [],
   "source": [
    "backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "streaming-check",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a strategy scope.\n",
    "with strategy.scope():\n",
    "    # Everything that creates variables should be under the strategy scope.\n",
    "    # In general this is only model construction & `compile()`.\n",
    "    conv_base, model = create_model()\n",
    "    model.compile(loss=losses.CategoricalCrossentropy(),\n",
    "                  optimizer=optimizers.Adam(learning_rate=lr_classifier),\n",
    "                  metrics=[metrics.CategoricalAccuracy()])\n",
    "\n",
    "model.load_weights(\n",
    "    os.path.join(\"transfer_learning_classifier_preprocess_input.h5\"),\n",
    "    by_name=False,\n",
    "    skip_mismatch=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fleet-blank",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_truediv (TensorFlow [(None, 299, 299, 3) 0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_sub (TensorFlowOpLa [(None, 299, 299, 3) 0           tf_op_layer_truediv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "xception (Model)                (None, 10, 10, 2048) 20861480    tf_op_layer_sub[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           xception[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d (GlobalMax (None, 2048)         0           xception[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 4096)         0           global_average_pooling2d[0][0]   \n",
      "                                                                 global_max_pooling2d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 4096)         16384       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 4096)         0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          2097664     dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 512)          2048        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 512)          0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 12)           6156        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 22,983,732\n",
      "Trainable params: 2,113,036\n",
      "Non-trainable params: 20,870,696\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "opposite-mouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.trainable = True\n",
    "\n",
    "set_trainable = False\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name == 'add_8':\n",
    "        set_trainable = True\n",
    "\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "equal-bloom",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_truediv (TensorFlow [(None, 299, 299, 3) 0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_sub (TensorFlowOpLa [(None, 299, 299, 3) 0           tf_op_layer_truediv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "xception (Model)                (None, 10, 10, 2048) 20861480    tf_op_layer_sub[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           xception[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d (GlobalMax (None, 2048)         0           xception[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 4096)         0           global_average_pooling2d[0][0]   \n",
      "                                                                 global_max_pooling2d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 4096)         16384       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 4096)         0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          2097664     dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 512)          2048        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 512)          0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 12)           6156        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 22,983,732\n",
      "Trainable params: 12,129,372\n",
      "Non-trainable params: 10,854,360\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=lr_tuning),\n",
    "                  loss=losses.CategoricalCrossentropy(),\n",
    "                  metrics=[metrics.CategoricalAccuracy()])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "popular-compilation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 300 steps, validate for 75 steps\n",
      "Epoch 1/12\n",
      "INFO:tensorflow:batch_all_reduce: 51 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:batch_all_reduce: 51 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "300/300 [==============================] - 143s 478ms/step - loss: 0.8266 - categorical_accuracy: 0.7347 - val_loss: 0.7001 - val_categorical_accuracy: 0.7717\n",
      "Epoch 2/12\n",
      "300/300 [==============================] - 134s 448ms/step - loss: 0.8412 - categorical_accuracy: 0.7290 - val_loss: 0.6964 - val_categorical_accuracy: 0.7733\n",
      "Epoch 3/12\n",
      "300/300 [==============================] - 135s 449ms/step - loss: 0.8252 - categorical_accuracy: 0.7320 - val_loss: 0.6947 - val_categorical_accuracy: 0.7742\n",
      "Epoch 4/12\n",
      "300/300 [==============================] - 134s 446ms/step - loss: 0.8147 - categorical_accuracy: 0.7385 - val_loss: 0.6939 - val_categorical_accuracy: 0.7754\n",
      "Epoch 5/12\n",
      "300/300 [==============================] - 135s 449ms/step - loss: 0.7943 - categorical_accuracy: 0.7452 - val_loss: 0.6920 - val_categorical_accuracy: 0.7771\n",
      "Epoch 6/12\n",
      "300/300 [==============================] - 134s 447ms/step - loss: 0.7830 - categorical_accuracy: 0.7499 - val_loss: 0.6916 - val_categorical_accuracy: 0.7775\n",
      "Epoch 7/12\n",
      "300/300 [==============================] - 134s 448ms/step - loss: 0.7995 - categorical_accuracy: 0.7483 - val_loss: 0.6884 - val_categorical_accuracy: 0.7779\n",
      "Epoch 8/12\n",
      "300/300 [==============================] - 135s 449ms/step - loss: 0.7986 - categorical_accuracy: 0.7428 - val_loss: 0.6895 - val_categorical_accuracy: 0.7792\n",
      "Epoch 9/12\n",
      "300/300 [==============================] - 136s 452ms/step - loss: 0.7931 - categorical_accuracy: 0.7476 - val_loss: 0.6867 - val_categorical_accuracy: 0.7779\n",
      "Epoch 10/12\n",
      "300/300 [==============================] - 137s 458ms/step - loss: 0.7829 - categorical_accuracy: 0.7476 - val_loss: 0.6877 - val_categorical_accuracy: 0.7804\n",
      "Epoch 11/12\n",
      "300/300 [==============================] - 137s 456ms/step - loss: 0.7826 - categorical_accuracy: 0.7452 - val_loss: 0.6841 - val_categorical_accuracy: 0.7808\n",
      "Epoch 12/12\n",
      "300/300 [==============================] - 137s 457ms/step - loss: 0.7790 - categorical_accuracy: 0.7474 - val_loss: 0.6838 - val_categorical_accuracy: 0.7800\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    epochs=epoch_tuning,\n",
    "                    validation_data=validation_generator,\n",
    "                    verbose=1,\n",
    "                    callbacks=my_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "modular-office",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "75/75 [==============================] - 11s 145ms/step - loss: 0.6838 - categorical_accuracy: 0.7800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6837612624963124, 0.78]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(validation_generator, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "composite-avatar",
   "metadata": {},
   "source": [
    "# Fine tune from add 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "current-defendant",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del (conv_base)\n",
    "    del (model)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "colonial-warning",
   "metadata": {},
   "outputs": [],
   "source": [
    "backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "optimum-plaza",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a strategy scope.\n",
    "with strategy.scope():\n",
    "    # Everything that creates variables should be under the strategy scope.\n",
    "    # In general this is only model construction & `compile()`.\n",
    "    conv_base, model = create_model()\n",
    "    model.compile(loss=losses.CategoricalCrossentropy(),\n",
    "                  optimizer=optimizers.Adam(learning_rate=lr_classifier),\n",
    "                  metrics=[metrics.CategoricalAccuracy()])\n",
    "\n",
    "model.load_weights(\n",
    "    os.path.join(\"transfer_learning_classifier_preprocess_input.h5\"),\n",
    "    by_name=False,\n",
    "    skip_mismatch=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "funded-miniature",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_truediv (TensorFlow [(None, 299, 299, 3) 0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_sub (TensorFlowOpLa [(None, 299, 299, 3) 0           tf_op_layer_truediv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "xception (Model)                (None, 10, 10, 2048) 20861480    tf_op_layer_sub[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           xception[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d (GlobalMax (None, 2048)         0           xception[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 4096)         0           global_average_pooling2d[0][0]   \n",
      "                                                                 global_max_pooling2d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 4096)         16384       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 4096)         0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          2097664     dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 512)          2048        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 512)          0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 12)           6156        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 22,983,732\n",
      "Trainable params: 2,113,036\n",
      "Non-trainable params: 20,870,696\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "hairy-resistance",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.trainable = True\n",
    "\n",
    "set_trainable = False\n",
    "for layer in conv_base.layers:\n",
    "    if layer.name == 'add_4':\n",
    "        set_trainable = True\n",
    "\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "destroyed-pleasure",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_truediv (TensorFlow [(None, 299, 299, 3) 0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_sub (TensorFlowOpLa [(None, 299, 299, 3) 0           tf_op_layer_truediv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "xception (Model)                (None, 10, 10, 2048) 20861480    tf_op_layer_sub[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           xception[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d (GlobalMax (None, 2048)         0           xception[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 4096)         0           global_average_pooling2d[0][0]   \n",
      "                                                                 global_max_pooling2d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 4096)         16384       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 4096)         0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          2097664     dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 512)          2048        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 512)          0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 12)           6156        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 22,983,732\n",
      "Trainable params: 18,585,276\n",
      "Non-trainable params: 4,398,456\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=lr_tuning),\n",
    "                  loss=losses.CategoricalCrossentropy(),\n",
    "                  metrics=[metrics.CategoricalAccuracy()])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "english-clone",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 300 steps, validate for 75 steps\n",
      "Epoch 1/12\n",
      "INFO:tensorflow:batch_all_reduce: 99 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:batch_all_reduce: 99 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "300/300 [==============================] - 150s 498ms/step - loss: 0.8299 - categorical_accuracy: 0.7381 - val_loss: 0.6999 - val_categorical_accuracy: 0.7733\n",
      "Epoch 2/12\n",
      "300/300 [==============================] - 138s 461ms/step - loss: 0.8241 - categorical_accuracy: 0.7347 - val_loss: 0.6990 - val_categorical_accuracy: 0.7738\n",
      "Epoch 3/12\n",
      "300/300 [==============================] - 138s 461ms/step - loss: 0.8167 - categorical_accuracy: 0.7402 - val_loss: 0.6962 - val_categorical_accuracy: 0.7763\n",
      "Epoch 4/12\n",
      "300/300 [==============================] - 138s 461ms/step - loss: 0.8067 - categorical_accuracy: 0.7390 - val_loss: 0.6920 - val_categorical_accuracy: 0.7775\n",
      "Epoch 5/12\n",
      "300/300 [==============================] - 139s 463ms/step - loss: 0.8019 - categorical_accuracy: 0.7468 - val_loss: 0.6884 - val_categorical_accuracy: 0.7808\n",
      "Epoch 6/12\n",
      "300/300 [==============================] - 138s 460ms/step - loss: 0.7981 - categorical_accuracy: 0.7469 - val_loss: 0.6881 - val_categorical_accuracy: 0.7804\n",
      "Epoch 7/12\n",
      "300/300 [==============================] - 138s 460ms/step - loss: 0.7724 - categorical_accuracy: 0.7536 - val_loss: 0.6853 - val_categorical_accuracy: 0.7817\n",
      "Epoch 8/12\n",
      "300/300 [==============================] - 138s 460ms/step - loss: 0.7782 - categorical_accuracy: 0.7544 - val_loss: 0.6819 - val_categorical_accuracy: 0.7817\n",
      "Epoch 9/12\n",
      "300/300 [==============================] - 138s 460ms/step - loss: 0.7694 - categorical_accuracy: 0.7475 - val_loss: 0.6843 - val_categorical_accuracy: 0.7821\n",
      "Epoch 10/12\n",
      "300/300 [==============================] - 139s 465ms/step - loss: 0.7815 - categorical_accuracy: 0.7513 - val_loss: 0.6809 - val_categorical_accuracy: 0.7837\n",
      "Epoch 11/12\n",
      "300/300 [==============================] - 139s 464ms/step - loss: 0.7601 - categorical_accuracy: 0.7578 - val_loss: 0.6774 - val_categorical_accuracy: 0.7837\n",
      "Epoch 12/12\n",
      "300/300 [==============================] - 140s 467ms/step - loss: 0.7505 - categorical_accuracy: 0.7556 - val_loss: 0.6755 - val_categorical_accuracy: 0.7825\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    epochs=epoch_tuning,\n",
    "                    validation_data=validation_generator,\n",
    "                    verbose=1,\n",
    "                    callbacks=my_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "threaded-austria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "75/75 [==============================] - 11s 144ms/step - loss: 0.6755 - categorical_accuracy: 0.7825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6755375293890635, 0.7825]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(validation_generator, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "therapeutic-ecology",
   "metadata": {},
   "source": [
    "# Fine tune all layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "active-queue",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del (conv_base)\n",
    "    del (model)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "identical-image",
   "metadata": {},
   "outputs": [],
   "source": [
    "backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "statutory-plaintiff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a strategy scope.\n",
    "with strategy.scope():\n",
    "    # Everything that creates variables should be under the strategy scope.\n",
    "    # In general this is only model construction & `compile()`.\n",
    "    conv_base, model = create_model()\n",
    "    model.compile(loss=losses.CategoricalCrossentropy(),\n",
    "                  optimizer=optimizers.Adam(learning_rate=lr_classifier),\n",
    "                  metrics=[metrics.CategoricalAccuracy()])\n",
    "\n",
    "model.load_weights(\n",
    "    os.path.join(\"transfer_learning_classifier_preprocess_input.h5\"),\n",
    "    by_name=False,\n",
    "    skip_mismatch=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "latest-premises",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_truediv (TensorFlow [(None, 299, 299, 3) 0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_sub (TensorFlowOpLa [(None, 299, 299, 3) 0           tf_op_layer_truediv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "xception (Model)                (None, 10, 10, 2048) 20861480    tf_op_layer_sub[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           xception[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d (GlobalMax (None, 2048)         0           xception[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 4096)         0           global_average_pooling2d[0][0]   \n",
      "                                                                 global_max_pooling2d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 4096)         16384       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 4096)         0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          2097664     dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 512)          2048        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 512)          0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 12)           6156        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 22,983,732\n",
      "Trainable params: 2,113,036\n",
      "Non-trainable params: 20,870,696\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "difficult-surname",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "favorite-reply",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_truediv (TensorFlow [(None, 299, 299, 3) 0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "tf_op_layer_sub (TensorFlowOpLa [(None, 299, 299, 3) 0           tf_op_layer_truediv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "xception (Model)                (None, 10, 10, 2048) 20861480    tf_op_layer_sub[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d (Globa (None, 2048)         0           xception[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling2d (GlobalMax (None, 2048)         0           xception[1][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 4096)         0           global_average_pooling2d[0][0]   \n",
      "                                                                 global_max_pooling2d[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 4096)         16384       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 4096)         0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          2097664     dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 512)          2048        dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 512)          0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 12)           6156        dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 22,983,732\n",
      "Trainable params: 22,919,988\n",
      "Non-trainable params: 63,744\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope():\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=lr_tuning),\n",
    "                  loss=losses.CategoricalCrossentropy(),\n",
    "                  metrics=[metrics.CategoricalAccuracy()])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "french-edition",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 300 steps, validate for 75 steps\n",
      "Epoch 1/12\n",
      "INFO:tensorflow:batch_all_reduce: 162 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:batch_all_reduce: 162 all-reduces with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "300/300 [==============================] - 199s 665ms/step - loss: 0.8102 - categorical_accuracy: 0.7432 - val_loss: 0.7018 - val_categorical_accuracy: 0.7721\n",
      "Epoch 2/12\n",
      "300/300 [==============================] - 188s 626ms/step - loss: 0.8119 - categorical_accuracy: 0.7447 - val_loss: 0.6977 - val_categorical_accuracy: 0.7746\n",
      "Epoch 3/12\n",
      "300/300 [==============================] - 188s 627ms/step - loss: 0.8089 - categorical_accuracy: 0.7403 - val_loss: 0.6903 - val_categorical_accuracy: 0.7771\n",
      "Epoch 4/12\n",
      "300/300 [==============================] - 188s 626ms/step - loss: 0.8034 - categorical_accuracy: 0.7429 - val_loss: 0.6891 - val_categorical_accuracy: 0.7758\n",
      "Epoch 5/12\n",
      "300/300 [==============================] - 188s 627ms/step - loss: 0.7878 - categorical_accuracy: 0.7452 - val_loss: 0.6859 - val_categorical_accuracy: 0.7767\n",
      "Epoch 6/12\n",
      "300/300 [==============================] - 188s 627ms/step - loss: 0.7867 - categorical_accuracy: 0.7447 - val_loss: 0.6836 - val_categorical_accuracy: 0.7783\n",
      "Epoch 7/12\n",
      "300/300 [==============================] - 188s 626ms/step - loss: 0.7623 - categorical_accuracy: 0.7551 - val_loss: 0.6806 - val_categorical_accuracy: 0.7800\n",
      "Epoch 8/12\n",
      "300/300 [==============================] - 188s 627ms/step - loss: 0.7494 - categorical_accuracy: 0.7498 - val_loss: 0.6760 - val_categorical_accuracy: 0.7842\n",
      "Epoch 9/12\n",
      "300/300 [==============================] - 188s 627ms/step - loss: 0.7569 - categorical_accuracy: 0.7582 - val_loss: 0.6728 - val_categorical_accuracy: 0.7854\n",
      "Epoch 10/12\n",
      "300/300 [==============================] - 188s 627ms/step - loss: 0.7430 - categorical_accuracy: 0.7576 - val_loss: 0.6724 - val_categorical_accuracy: 0.7846\n",
      "Epoch 11/12\n",
      "300/300 [==============================] - 188s 628ms/step - loss: 0.7596 - categorical_accuracy: 0.7530 - val_loss: 0.6702 - val_categorical_accuracy: 0.7862\n",
      "Epoch 12/12\n",
      "300/300 [==============================] - 188s 626ms/step - loss: 0.7364 - categorical_accuracy: 0.7582 - val_loss: 0.6701 - val_categorical_accuracy: 0.7862\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    epochs=epoch_tuning,\n",
    "                    validation_data=validation_generator,\n",
    "                    verbose=1,\n",
    "                    callbacks=my_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "experienced-realtor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "75/75 [==============================] - 11s 148ms/step - loss: 0.6701 - categorical_accuracy: 0.7862\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6701074024041493, 0.78625]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(validation_generator, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
