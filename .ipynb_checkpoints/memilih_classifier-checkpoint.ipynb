{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "hungarian-consent",
   "metadata": {},
   "source": [
    "# Object Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "employed-holmes",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "republican-banner",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import Xception\n",
    "from tensorflow.keras.applications.xception import preprocess_input\n",
    "from tensorflow.keras import models, layers, utils\n",
    "from tensorflow.keras import losses, metrics, optimizers\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "documented-accounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define our working directory\n",
    "dir_img_train = \"dataset/subset/train/\"\n",
    "dir_img_validation = \"dataset/subset/validation/\"\n",
    "dir_img_test = \"dataset/subset/test/\"\n",
    "save_dir = os.path.join(\"models/\")\n",
    "\n",
    "img_size = (299, 299, 3)\n",
    "batch_size = 16\n",
    "\n",
    "lr_classifier = 1e-4\n",
    "epoch_classifier = 10\n",
    "\n",
    "lr_tuning = 1e-6\n",
    "epoch_tuning = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ideal-platform",
   "metadata": {},
   "source": [
    "## Prepare Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "explicit-punishment",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = image.ImageDataGenerator(rotation_range=40,\n",
    "                                         width_shift_range=0.2,\n",
    "                                         height_shift_range=0.2,\n",
    "                                         shear_range=0.2,\n",
    "                                         zoom_range=0.2,\n",
    "                                         horizontal_flip=True,\n",
    "                                         fill_mode=\"nearest\")\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen = image.ImageDataGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intermediate-virgin",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_directory(dir_img_train,\n",
    "                                                    target_size=img_size[:2],\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode=\"categorical\",\n",
    "                                                    shuffle=True,\n",
    "                                                    seed=1234)\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    dir_img_validation,\n",
    "    target_size=img_size[:2],\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    shuffle=True,\n",
    "    seed=1234)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(dir_img_test,\n",
    "                                                  target_size=img_size[:2],\n",
    "                                                  batch_size=batch_size,\n",
    "                                                  class_mode=\"categorical\",\n",
    "                                                  shuffle=True,\n",
    "                                                  seed=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "promising-rolling",
   "metadata": {},
   "source": [
    "### Cek Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "matched-david",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worse-smooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_idx = train_generator.index_array[1]\n",
    "train_generator.labels[image_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepared-pastor",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = train_generator.filenames[image_idx]\n",
    "fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retired-prisoner",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images_7, train_labels_7 = train_generator[7]\n",
    "print(train_images_7.shape)\n",
    "print(train_labels_7.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sticky-miracle",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "for idx in range(16):\n",
    "    ax = plt.subplot(4, 4, idx + 1)\n",
    "    plt.imshow(image.array_to_img(train_images_7[idx]))\n",
    "    plt.title(str(train_labels_7[idx]))\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "separate-niger",
   "metadata": {},
   "source": [
    "### Cek Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standing-james",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_generator[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "first-advocacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_idx = validation_generator.index_array[1]\n",
    "validation_generator.labels[image_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "controversial-eleven",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = validation_generator.filenames[image_idx]\n",
    "fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chubby-cabinet",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_images_7, validation_labels_7 = validation_generator[7]\n",
    "print(validation_images_7.shape)\n",
    "print(validation_labels_7.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "editorial-energy",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 20))\n",
    "\n",
    "for idx in range(16):\n",
    "    ax = plt.subplot(4, 4, idx + 1)\n",
    "    plt.imshow(image.array_to_img(validation_images_7[idx]))\n",
    "    plt.title(str(validation_labels_7[idx]))\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "judicial-evaluation",
   "metadata": {},
   "source": [
    "## Define Model with multi GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "apparent-luther",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_keras():\n",
    "    conv_base = Xception(weights=\"imagenet\",\n",
    "                         include_top=False,\n",
    "                         input_shape=img_size)\n",
    "\n",
    "    conv_base.trainable = False\n",
    "\n",
    "    input_layer = keras.Input(shape=img_size)\n",
    "    x = preprocess_input(input_layer)\n",
    "    x = conv_base(x, training=False)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    output_layer = layers.Dense(12, activation=\"softmax\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    return conv_base, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "physical-sandwich",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_fastai():\n",
    "    conv_base = Xception(weights=\"imagenet\",\n",
    "                         include_top=False,\n",
    "                         input_shape=img_size)\n",
    "\n",
    "    conv_base.trainable = False\n",
    "\n",
    "    input_layer = keras.Input(shape=img_size)\n",
    "    x = preprocess_input(input_layer)\n",
    "    x = conv_base(x, training=False)\n",
    "    x1 = layers.GlobalAveragePooling2D()(x)\n",
    "    x2 = layers.GlobalMaxPooling2D()(x)\n",
    "    x = layers.Concatenate()([x1, x2])\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(512, activation=\"relu\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    output_layer = layers.Dense(12, activation=\"softmax\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    return conv_base, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "looking-championship",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_sazzad():\n",
    "    conv_base = Xception(weights=\"imagenet\",\n",
    "                         include_top=False,\n",
    "                         input_shape=img_size)\n",
    "\n",
    "    conv_base.trainable = False\n",
    "\n",
    "    input_layer = keras.Input(shape=img_size)\n",
    "    x = preprocess_input(input_layer)\n",
    "    x = conv_base(x, training=False)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    x = layers.Dense(1024, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    output_layer = layers.Dense(12, activation=\"softmax\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    return conv_base, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "billion-change",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_random():\n",
    "    conv_base = Xception(weights=\"imagenet\",\n",
    "                         include_top=False,\n",
    "                         input_shape=img_size)\n",
    "\n",
    "    conv_base.trainable = False\n",
    "\n",
    "    input_layer = keras.Input(shape=img_size)\n",
    "    x = preprocess_input(input_layer)\n",
    "    x = conv_base(x, training=False)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    output_layer = layers.Dense(12, activation=\"softmax\")(x)\n",
    "\n",
    "    model = keras.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    return conv_base, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ethical-residence",
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print(\"Number of devices: {}\".format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proof-engineer",
   "metadata": {},
   "source": [
    "## Training Clasifier Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "everyday-consultation",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del (conv_base)\n",
    "    del (model)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elder-perth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a strategy scope.\n",
    "with strategy.scope():\n",
    "    # Everything that creates variables should be under the strategy scope.\n",
    "    # In general this is only model construction & `compile()`.\n",
    "    conv_base, model = create_model_keras()\n",
    "    model.compile(loss=losses.CategoricalCrossentropy(),\n",
    "                  optimizer=optimizers.Adam(learning_rate=lr_classifier),\n",
    "                  metrics=[metrics.CategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "expensive-joining",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nervous-passion",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_model(model, show_layer_names=True, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "graphic-square",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    epochs=epoch_classifier,\n",
    "                    validation_data=validation_generator,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepared-banking",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superior-catalyst",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = history.history['categorical_accuracy']\n",
    "val_accuracy = history.history['val_categorical_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(accuracy))\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, accuracy, label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, label='Validation accuracy')\n",
    "plt.title('Training and validation accuracyuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, loss, label='Training loss')\n",
    "plt.plot(epochs, val_loss, label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "little-standing",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genuine-eleven",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_generator, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hollywood-conference",
   "metadata": {},
   "source": [
    "## Training Clasifier Fastai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "close-festival",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a strategy scope.\n",
    "with strategy.scope():\n",
    "    # Everything that creates variables should be under the strategy scope.\n",
    "    # In general this is only model construction & `compile()`.\n",
    "    conv_base, model = create_model_fastai()\n",
    "    model.compile(loss=losses.CategoricalCrossentropy(),\n",
    "                  optimizer=optimizers.Adam(learning_rate=lr_classifier),\n",
    "                  metrics=[metrics.CategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "selective-pocket",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "raised-winning",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_model(model, show_layer_names=True, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sealed-machine",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    epochs=epoch_classifier,\n",
    "                    validation_data=validation_generator,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diverse-expansion",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "running-truck",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = history.history['categorical_accuracy']\n",
    "val_accuracy = history.history['val_categorical_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(accuracy))\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, accuracy, label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, label='Validation accuracy')\n",
    "plt.title('Training and validation accuracyuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, loss, label='Training loss')\n",
    "plt.plot(epochs, val_loss, label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funny-cosmetic",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "potential-bullet",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_generator, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advisory-madrid",
   "metadata": {},
   "source": [
    "## Training Clasifier Sazzad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honey-earth",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del (conv_base)\n",
    "    del (model)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surrounded-greenhouse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a strategy scope.\n",
    "with strategy.scope():\n",
    "    # Everything that creates variables should be under the strategy scope.\n",
    "    # In general this is only model construction & `compile()`.\n",
    "    conv_base, model = create_model_sazzad()\n",
    "    model.compile(loss=losses.CategoricalCrossentropy(),\n",
    "                  optimizer=optimizers.Adam(learning_rate=lr_classifier),\n",
    "                  metrics=[metrics.CategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corresponding-occurrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "massive-karen",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_model(model, show_layer_names=True, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-artwork",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    epochs=epoch_classifier,\n",
    "                    validation_data=validation_generator,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regional-graham",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "important-concert",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = history.history['categorical_accuracy']\n",
    "val_accuracy = history.history['val_categorical_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(accuracy))\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, accuracy, label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, label='Validation accuracy')\n",
    "plt.title('Training and validation accuracyuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, loss, label='Training loss')\n",
    "plt.plot(epochs, val_loss, label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spatial-contract",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "defined-genetics",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_generator, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pleasant-modern",
   "metadata": {},
   "source": [
    "## Training Clasifier Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brave-drive",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    del (conv_base)\n",
    "    del (model)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "indian-warning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open a strategy scope.\n",
    "with strategy.scope():\n",
    "    # Everything that creates variables should be under the strategy scope.\n",
    "    # In general this is only model construction & `compile()`.\n",
    "    conv_base, model = create_model_random()\n",
    "    model.compile(loss=losses.CategoricalCrossentropy(),\n",
    "                  optimizer=optimizers.Adam(learning_rate=lr_classifier),\n",
    "                  metrics=[metrics.CategoricalAccuracy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "excessive-fossil",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "together-indianapolis",
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.plot_model(model, show_layer_names=True, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescription-secondary",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = model.fit(train_generator,\n",
    "                    epochs=epoch_classifier,\n",
    "                    validation_data=validation_generator,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finite-ethernet",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weird-characteristic",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = history.history['categorical_accuracy']\n",
    "val_accuracy = history.history['val_categorical_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(accuracy))\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, accuracy, label='Training accuracy')\n",
    "plt.plot(epochs, val_accuracy, label='Validation accuracy')\n",
    "plt.title('Training and validation accuracyuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, loss, label='Training loss')\n",
    "plt.plot(epochs, val_loss, label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "furnished-comedy",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "homeless-transport",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_generator, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suspended-tanzania",
   "metadata": {},
   "source": [
    "# Take away:\n",
    "\n",
    "- Pay attention to your model (loss and accuracy or other metrics) :\n",
    "    - overfit : if the model is too much capacity to recognize all pattern in the dataset\n",
    "    - underfit : if the model is lack capacity to get the pattern from dataset\n",
    "- More neuron / bigger model / deeper model : better pattern recognition\n",
    "    - too big --> overfit\n",
    "    - too small --> underfit\n",
    "- Follow the well-known practitioner / paper"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "376.8px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
